environment:
  distributed: False
  backend: 'nccl'

checkpoint:
  monitor: 'loss'
  save_every: 1
  max_to_keep: 10
  initial_value_threshold: 0.2
  verbose: True

model:
  name: 'MLP'
  number_of_layers: 5
  neurons_per_layer: [1024, 2048, 2048, 1024, 1]
  activation: ReLU
  dropout_rates: 0.0, 0.0, 0.0, 0.0, 0.0]

#model:
#  name: 'Conv1d'
#  block: '01'
#  in_channels: 2
#  out_channels: [32, 64, 128]
#  batch_norm: False
#  activation: 'ReLU'
#  conv_layers: 3
#  dropout_rate: 0.0

#model:
#  name: 'LSTM'
#  input_size: 2
#  hidden_size: 128
#  num_layers: 2
#  batch_first: True
#  dropout: 0.0
#  bidirectional: False

#model:
#  input_dim: 2
#  d_model: 64
#  nhead: 4
#  num_layers: 2
#  dropout: 0.2
#  max_len: 2048
#  out_features: 1

optimizer:
  type: 'Adam'
  params:
    lr: 0.0003

#lr_scheduler:
#  type: ExponentialLR
#  params:
#    gamma: 0.9

#lr_scheduler:
#  type: ReduceLROnPlateau
#  params:
#    mode: 'min'
#    factor: 0.1
#    patience: 10
#    threshold: 0.0001

dataset:
  input_folder: "../dataset/chirikov02"
  output_folder: "../output"
  sequence_length: 512
  num_trajectories:

dataloader:
  batch_size: 32
  num_workers: 1
  persistent_workers: True

trainer:
  loss: 'SmoothL1Loss'
  metrics: 'SL1'
  epochs: 100
  save_img_every: 10
  gpu_id:
  verbose: True
